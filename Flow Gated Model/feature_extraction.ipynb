{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpticalFlow(video):\n",
    "\n",
    "    gray_video = []\n",
    "    for i in range(len(video)):\n",
    "        img = cv2.cvtColor(video[i], cv2.COLOR_RGB2GRAY)\n",
    "        gray_video.append(np.reshape(img,(224,224,1)))\n",
    "\n",
    "    flows = []\n",
    "    for i in range(0,len(video)-1):\n",
    "        flow = cv2.calcOpticalFlowFarneback(gray_video[i], gray_video[i+1], None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "        flow[..., 0] -= np.mean(flow[..., 0])\n",
    "        flow[..., 1] -= np.mean(flow[..., 1])\n",
    "        flow[..., 0] = cv2.normalize(flow[..., 0],None,0,255,cv2.NORM_MINMAX)\n",
    "        flow[..., 1] = cv2.normalize(flow[..., 1],None,0,255,cv2.NORM_MINMAX)\n",
    "        flows.append(flow)\n",
    "        \n",
    "    flows.append(np.zeros((224,224,2)))\n",
    "      \n",
    "    return np.array(flows, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Video2Npy(file_path, resize=(224,224)):\n",
    "   \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    len_frames = int(cap.get(7))\n",
    "    \n",
    "    try:\n",
    "        frames = []\n",
    "        for i in range(len_frames-1):\n",
    "            _, frame = cap.read()\n",
    "            frame = cv2.resize(frame,resize, interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = np.reshape(frame, (224,224,3))\n",
    "            frames.append(frame)   \n",
    "    except:\n",
    "        print(\"Error: \", file_path, len_frames,i)\n",
    "    finally:\n",
    "        frames = np.array(frames)\n",
    "        cap.release()\n",
    "            \n",
    "    flows = getOpticalFlow(frames)\n",
    "    \n",
    "    result = np.zeros((len(flows),224,224,5))\n",
    "    result[...,:3] = frames\n",
    "    result[...,3:] = flows\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save2Npy(file_dir, save_dir):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    videos = os.listdir(file_dir)\n",
    "    \n",
    "    for v in tqdm(videos):\n",
    "        video_name = v.split('.')[0]\n",
    "        video_path = os.path.join(file_dir, v)\n",
    "        save_path = os.path.join(save_dir, video_name+'.npy') \n",
    "        data = Video2Npy(file_path=video_path, resize=(224,224))\n",
    "        data = np.uint8(data)\n",
    "        np.save(save_path, data)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"./dataset\"\n",
    "target_path = \"./dataset/features\"\n",
    "\n",
    "for f1 in ['train', 'val']:\n",
    "    for f2 in ['Fight', 'NonFight']:\n",
    "        path1 = os.path.join(source_path, f1, f2)\n",
    "        path2 = os.path.join(target_path, f1, f2)\n",
    "        Save2Npy(file_dir=path1, save_dir=path2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
